{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2735c935",
   "metadata": {
    "id": "2735c935"
   },
   "source": [
    "<h1><center> Assignment 1: EDA United Nations General Debate Corpus  </center></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c94a6",
   "metadata": {},
   "source": [
    "## Read UNGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0b3ce3",
   "metadata": {
    "id": "cd0b3ce3",
    "outputId": "2389f396-4af3-408f-ead4-16e595e79676"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/wolfson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pickle\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "\n",
    "sessions = np.arange(25, 78)\n",
    "data=[]\n",
    "\n",
    "for session in sessions:\n",
    "    directory = \"./TXT/Session \"+str(session)+\" - \"+str(1945+session)\n",
    "    for filename in os.listdir(directory):\n",
    "        f = open(os.path.join(directory, filename), encoding = \"utf8\")\n",
    "        if filename[0]==\".\": #ignore hidden files\n",
    "            continue\n",
    "        splt = filename.split(\"_\")\n",
    "        data.append([session, 1945+session, splt[0], f.read()])\n",
    "\n",
    "        \n",
    "df_speech = pd.DataFrame(data, columns=['Session','Year','ISO-alpha3 Code','Speech'])\n",
    "df_codes = pd.read_csv('UNSD — Methodology.csv', sep=';')\n",
    "\n",
    "df_un_merged = df_speech.merge(df_codes[['Country or Area','ISO-alpha3 Code', 'Region Name']], how='left', left_on='ISO-alpha3 Code', right_on='ISO-alpha3 Code')\n",
    "df_un_merged.set_index(['Year','ISO-alpha3 Code'], inplace=True)\n",
    "df_un_merged[\"Speech\"] = df_un_merged[\"Speech\"].str.lower()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e7b45",
   "metadata": {},
   "source": [
    "## Load/Create Sentiment Intensity Analyzer and merge it with UN data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0571bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "try:\n",
    "    with open('sia.pickle', 'rb') as handle:\n",
    "        sia_columns = pickle.load(handle)\n",
    "except:\n",
    "    x=df_un_merged[\"Speech\"].apply(sia.polarity_scores)\n",
    "    sia_columns = pd.DataFrame(x.to_list())\n",
    "    with open('sia.pickle', 'wb') as handle:\n",
    "        pickle.dump(sia_colomns, handle)\n",
    "\n",
    "df_un_merged = df_un_merged.reset_index().merge(sia_columns, how='left', left_index=True, right_index=True)\n",
    "df_un_merged.set_index(['Year','ISO-alpha3 Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6a14ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>Speech</th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>ISO-alpha3 Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1970</th>\n",
       "      <th>LBR</th>\n",
       "      <td>25</td>\n",
       "      <td>49.\\t it gives me great pleasure, mr. presiden...</td>\n",
       "      <td>Liberia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTO</th>\n",
       "      <td>25</td>\n",
       "      <td>135.\\t  before commencing my statement, i shou...</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KWT</th>\n",
       "      <td>25</td>\n",
       "      <td>1.\\t   mr. president, your election to the aug...</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>Asia</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOM</th>\n",
       "      <td>25</td>\n",
       "      <td>107.\\t it is with great pleasure that my deleg...</td>\n",
       "      <td>Somalia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDN</th>\n",
       "      <td>25</td>\n",
       "      <td>126.\\t in this anniversary year the general as...</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020</th>\n",
       "      <th>PRY</th>\n",
       "      <td>75</td>\n",
       "      <td>president of the general assembly,\\nexcellenci...</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAM</th>\n",
       "      <td>75</td>\n",
       "      <td>your excellency, volkan bozkir, president of t...</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <th>UKR</th>\n",
       "      <td>76</td>\n",
       "      <td>only pronounced in the un general assembly in ...</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022</th>\n",
       "      <th>RUS</th>\n",
       "      <td>77</td>\n",
       "      <td>seventy-seventh session,\\n \\n12th &amp; 13th meeti...</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.9417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKR</th>\n",
       "      <td>77</td>\n",
       "      <td>statement\\nby president of ukraine h.e. mr. vo...</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.9366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8484 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Session  \\\n",
       "Year ISO-alpha3 Code            \n",
       "1970 LBR                   25   \n",
       "     TTO                   25   \n",
       "     KWT                   25   \n",
       "     SOM                   25   \n",
       "     SDN                   25   \n",
       "...                       ...   \n",
       "2020 PRY                   75   \n",
       "     NAM                   75   \n",
       "2021 UKR                   76   \n",
       "2022 RUS                   77   \n",
       "     UKR                   77   \n",
       "\n",
       "                                                                 Speech  \\\n",
       "Year ISO-alpha3 Code                                                      \n",
       "1970 LBR              49.\\t it gives me great pleasure, mr. presiden...   \n",
       "     TTO              135.\\t  before commencing my statement, i shou...   \n",
       "     KWT              1.\\t   mr. president, your election to the aug...   \n",
       "     SOM              107.\\t it is with great pleasure that my deleg...   \n",
       "     SDN              126.\\t in this anniversary year the general as...   \n",
       "...                                                                 ...   \n",
       "2020 PRY              president of the general assembly,\\nexcellenci...   \n",
       "     NAM              your excellency, volkan bozkir, president of t...   \n",
       "2021 UKR              only pronounced in the un general assembly in ...   \n",
       "2022 RUS              seventy-seventh session,\\n \\n12th & 13th meeti...   \n",
       "     UKR              statement\\nby president of ukraine h.e. mr. vo...   \n",
       "\n",
       "                          Country or Area Region Name    neg    neu    pos  \\\n",
       "Year ISO-alpha3 Code                                                         \n",
       "1970 LBR                          Liberia      Africa  0.080  0.719  0.201   \n",
       "     TTO              Trinidad and Tobago    Americas  0.040  0.816  0.144   \n",
       "     KWT                           Kuwait        Asia  0.082  0.760  0.158   \n",
       "     SOM                          Somalia      Africa  0.105  0.731  0.163   \n",
       "     SDN                            Sudan      Africa  0.113  0.730  0.157   \n",
       "...                                   ...         ...    ...    ...    ...   \n",
       "2020 PRY                         Paraguay    Americas  0.098  0.725  0.177   \n",
       "     NAM                          Namibia      Africa  0.067  0.721  0.213   \n",
       "2021 UKR                          Ukraine      Europe  0.084  0.779  0.137   \n",
       "2022 RUS               Russian Federation      Europe  0.128  0.736  0.136   \n",
       "     UKR                          Ukraine      Europe  0.167  0.661  0.172   \n",
       "\n",
       "                      compound  \n",
       "Year ISO-alpha3 Code            \n",
       "1970 LBR                1.0000  \n",
       "     TTO                0.9999  \n",
       "     KWT                0.9997  \n",
       "     SOM                0.9999  \n",
       "     SDN                0.9997  \n",
       "...                        ...  \n",
       "2020 PRY                0.9964  \n",
       "     NAM                0.9997  \n",
       "2021 UKR                0.9993  \n",
       "2022 RUS                0.9417  \n",
       "     UKR               -0.9366  \n",
       "\n",
       "[8484 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_un_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804ea16",
   "metadata": {},
   "source": [
    "## Run bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(lowercase=True, \\\n",
    "                             stop_words='english',\\\n",
    "                             analyzer='word',\\\n",
    "                            token_pattern=r\"[a-z]+'?[a-z]+\", \\\n",
    "                            min_df=100, ngram_range=(1,1))\n",
    "\n",
    "count_vect_bigram = CountVectorizer(lowercase=True, \\\n",
    "                             stop_words='english',\\\n",
    "                             analyzer='word',\\\n",
    "                            token_pattern=r\"[a-z]+'?[a-z]+\", \\\n",
    "                            min_df=100, ngram_range=(2,2))\n",
    "\n",
    "X_counts = count_vect.fit_transform(df_un_merged[\"Speech\"])\n",
    "X_counts_bigram = count_vect_bigram.fit_transform(df_un_merged[\"Speech\"])\n",
    "\n",
    "X_counts_tf = TfidfTransformer(use_idf=True).fit_transform(X_counts)\n",
    "words_list = count_vect.get_feature_names_out()\n",
    "words_list_bigram = count_vect_bigram.get_feature_names_out()\n",
    "X_counts = pd.DataFrame(X_counts.toarray(), columns=words_list)\n",
    "X_counts_bigram = pd.DataFrame(X_counts_bigram.toarray(), columns=words_list_bigram)\n",
    "#X_counts = pd.DataFrame(X_counts_tf.toarray(), columns=words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3217b0",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_words = X_counts.sum().sort_values(ascending=False)\n",
    "amount_of_words_bigram = X_counts_bigram.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(scale = 10, random_state = 1, max_font_size=100, background_color=\"white\", colormap=\"inferno\")\\\n",
    ".generate_from_frequencies(amount_of_words)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(scale = 10, random_state = 1, max_font_size=100, background_color=\"white\", colormap=\"inferno\")\\\n",
    ".generate_from_frequencies(amount_of_words_bigram)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ae3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "colors = sns.color_palette('inferno')\n",
    "\n",
    "amount_of_words[0:10].plot.bar(color = colors)\n",
    "plt.xticks(rotation=30, ha = 'right')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 most used words\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "amount_of_words_bigram[0:10].plot.bar(color = colors)\n",
    "plt.xticks(rotation=30, ha = 'right')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 most used combination of words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87532eb",
   "metadata": {},
   "source": [
    "## Merge UNGDC with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f164286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un_merged = df_un_merged.reset_index().merge(X_counts, how='left', left_index=True, right_index=True)\n",
    "df_un_merged.set_index(['Year','ISO-alpha3 Code'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625760ad",
   "metadata": {},
   "source": [
    "## Read happiness report and merge with country codes to get ISO-alpha3 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aa614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happinessdataframe = pd.read_excel('DataForTable2.1.xls')\n",
    "df_happiness_merged = happinessdataframe.merge(df_codes[['Country or Area','ISO-alpha3 Code']], how='left', left_on='Country name', right_on='Country or Area')\n",
    "df_happiness_merged.set_index(['year','ISO-alpha3 Code'], inplace=True)\n",
    "df_happiness_merged.index.rename(['Year','ISO-alpha3 Code'], inplace=True)\n",
    "df_happiness_merged.drop(columns=['Country name','Country or Area'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70614e",
   "metadata": {},
   "source": [
    "## Read HDI report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDI = pd.read_csv('HDI.csv')\n",
    "HDI.sort_values(by=['Year'], inplace = True)\n",
    "HDI.set_index(['Year', 'Code'], inplace = True)\n",
    "HDI.drop(columns=['Entity'], inplace=True)\n",
    "HDI.index.rename(['Year','ISO-alpha3 Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58defa",
   "metadata": {},
   "source": [
    "## Merge UNGDC with happiness report and HDI by Multiple index Year, ISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9710c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_un_merged.merge(df_happiness_merged, how='left', left_index=True, right_index=True)\n",
    "df_merged = df_merged.merge(HDI, how='left', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67242e61",
   "metadata": {},
   "source": [
    "## Select only 2005-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_05_20 = df_merged.loc[2005:2020,:] \n",
    "df_merged_05_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3d85b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Group dataset by region\n",
    "eur = df_merged_05_20[df_merged_05_20['Region Name'] == 'Europe']\n",
    "afr = df_merged_05_20[df_merged_05_20['Region Name'] == 'Africa']\n",
    "ame = df_merged_05_20[df_merged_05_20['Region Name'] == 'Americas']\n",
    "asi = df_merged_05_20[df_merged_05_20['Region Name'] == 'Asia']\n",
    "oce = df_merged_05_20[df_merged_05_20['Region Name'] == 'Oceania']\n",
    "\n",
    "print('nr European countries:', eur['Country or Area'].nunique())\n",
    "print('nr African countries:', afr['Country or Area'].nunique())\n",
    "print('nr American countries:', ame['Country or Area'].nunique())\n",
    "print('nr Asian countries:', asi['Country or Area'].nunique())\n",
    "print('nr Oceanean countries:', oce['Country or Area'].nunique())\n",
    "\n",
    "#Group by means per year\n",
    "eur_means = eur.groupby('Year').aggregate(np.nanmean)\n",
    "afr_means = afr.groupby('Year').aggregate(np.nanmean)\n",
    "ame_means = ame.groupby('Year').aggregate(np.nanmean)\n",
    "asi_means = asi.groupby('Year').aggregate(np.nanmean)\n",
    "oce_means = oce.groupby('Year').aggregate(np.nanmean)\n",
    "\n",
    "#Get the count of the usage of the word 'climate' in speeches\n",
    "eur_climate = eur[['climate']].groupby('Year').mean()\n",
    "afr_climate = afr[['climate']].groupby('Year').mean()\n",
    "ame_climate = ame[['climate']].groupby('Year').mean()\n",
    "asi_climate = asi[['climate']].groupby('Year').mean()\n",
    "oce_climate = oce[['climate']].groupby('Year').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f9ecc",
   "metadata": {},
   "source": [
    "## Create speeches countplot per region from 2005 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af835332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot per region (absolute counts)\n",
    "plt.plot(eur_climate, label = \"Europe\")\n",
    "plt.plot(afr_climate, label = \"Africa\")\n",
    "plt.plot(asi_climate, label = \"Asia\")\n",
    "plt.plot(ame_climate, label = \"Americas\")\n",
    "plt.plot(oce_climate, label = \"Oceania\")\n",
    "plt.legend(loc=2, prop={'size': 12})\n",
    "plt.title(label = 'Mean count of the word climate in UN speeches from 2005 to 2020')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean count')\n",
    "\n",
    "# #Plot per region (relative counts to nr of countries per region)\n",
    "# plt.plot(eur_climate / eur['Country or Area'].nunique(), label = \"Europe\")\n",
    "# plt.plot(afr_climate / afr['Country or Area'].nunique(), label = \"Africa\")\n",
    "# plt.plot(asi_climate / asi['Country or Area'].nunique(), label = \"Asia\")\n",
    "# plt.plot(ame_climate / ame['Country or Area'].nunique(), label = \"Americas\")\n",
    "# plt.plot(oce_climate / oce['Country or Area'].nunique(), label = \"Oceania\")\n",
    "# plt.legend(loc=2, prop={'size': 12})\n",
    "# plt.title(label = 'Mean count of the word climate in UN speeches from 2005 to 2020')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Mean count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(eur['climate'], eur['Life Ladder'], label = \"Europe\")\n",
    "# plt.scatter(afr['climate'], afr['Life Ladder'], label = \"Africa\")\n",
    "# plt.scatter(asi['climate'], asi['Life Ladder'], label = \"Asia\")\n",
    "# plt.scatter(ame['climate'], ame['Life Ladder'], label = \"Americas\")\n",
    "# plt.scatter(oce['climate'], oce['Life Ladder'], label = \"Oceania\")\n",
    "plt.legend(loc=4, prop={'size': 10})\n",
    "plt.xlabel('climate mean')\n",
    "plt.ylabel('Life Ladder mean')\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(eur_climate['climate'], eur_means['Human Development Index (UNDP)'], label = \"Europe\")\n",
    "plt.scatter(afr_climate['climate'], afr_means['Human Development Index (UNDP)'], label = \"Africa\")\n",
    "plt.scatter(asi_climate['climate'], asi_means['Human Development Index (UNDP)'], label = \"Asia\")\n",
    "plt.scatter(ame_climate['climate'], ame_means['Human Development Index (UNDP)'], label = \"Americas\")\n",
    "plt.scatter(oce_climate['climate'], oce_means['Human Development Index (UNDP)'], label = \"Oceania\")\n",
    "plt.legend(loc=4, prop={'size': 10})\n",
    "plt.xlabel('climate mean')\n",
    "plt.ylabel('Human Development Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = [eur.shape[0], afr.shape[0], asi.shape[0], ame.shape[0], oce.shape[0]]\n",
    "lst2 = [eur['Country or Area'].nunique(), afr['Country or Area'].nunique(), asi['Country or Area'].nunique(), ame['Country or Area'].nunique(), oce['Country or Area'].nunique()]\n",
    "\n",
    "speeches_count_regions = pd.DataFrame(list(zip(lst1, lst2)), columns = ['Number of speeches', 'Number of countries'], index = ['Europe', 'Africa', 'Asia', 'Americas', 'Oceania'])\n",
    "speeches_count_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785e700",
   "metadata": {},
   "source": [
    "## Create plots for Life ladder, GDP and HDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedce4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots of happiness indicators\n",
    "plt.figure(1)\n",
    "plt.plot(eur_means['Life Ladder'], label = \"Europe\")\n",
    "plt.plot(afr_means['Life Ladder'], label = \"Africa\")\n",
    "plt.plot(asi_means['Life Ladder'], label = \"Asia\")\n",
    "plt.plot(ame_means['Life Ladder'], label = \"Americas\")\n",
    "plt.plot(oce_means['Life Ladder'], label = \"Oceania\")\n",
    "plt.legend(loc=2, prop={'size': 10})\n",
    "plt.title(label = 'Life ladder')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Life ladder')\n",
    "plt.xticks(np.arange(2005, 2020, step=2))\n",
    "\n",
    "# plt.plot(eur_means['Log GDP per capita'], label = \"Europe\")\n",
    "# plt.plot(afr_means['Log GDP per capita'], label = \"Africa\")\n",
    "# plt.plot(asi_means['Log GDP per capita'], label = \"Asia\")\n",
    "# plt.plot(ame_means['Log GDP per capita'], label = \"Americas\")\n",
    "# plt.plot(oce_means['Log GDP per capita'], label = \"Oceania\")\n",
    "# plt.legend(loc=2, prop={'size': 10})\n",
    "# plt.title(label = 'Log GDP')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Log GDP')\n",
    "# plt.xticks(np.arange(2005, 2020, step=2))\n",
    "plt.figure(2)\n",
    "\n",
    "plt.plot(eur_means['Human Development Index (UNDP)'], label = \"Europe\")\n",
    "plt.plot(afr_means['Human Development Index (UNDP)'], label = \"Africa\")\n",
    "plt.plot(asi_means['Human Development Index (UNDP)'], label = \"Asia\")\n",
    "plt.plot(ame_means['Human Development Index (UNDP)'], label = \"Americas\")\n",
    "plt.plot(oce_means['Human Development Index (UNDP)'], label = \"Oceania\")\n",
    "plt.legend(loc=2, prop={'size': 10})\n",
    "plt.title(label = 'HDI')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('HDI')\n",
    "plt.xticks(np.arange(2005, 2020, step=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57775e",
   "metadata": {},
   "source": [
    "### Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a104d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# remove na from rows\n",
    "x=df_merged_05_20.dropna(subset=['Life Ladder'])\n",
    "y = x['Life Ladder'].values\n",
    "\n",
    "features=['pos','neg']\n",
    "features.extend(amount_of_words[2:20].keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# splitting the data\n",
    "x_rem, x_test, y_rem, y_test = train_test_split(x, y, test_size=0.3, random_state = 42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_rem, y_rem, test_size=0.3, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cf308",
   "metadata": {},
   "source": [
    "### Hyperparameters tunning based grid search on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ee816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create grid of parameters to test through cross-validation\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(1,5)}\n",
    "\n",
    "pipe = make_pipeline( PolynomialFeatures(), LinearRegression())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(x_valid[features], y_valid);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb084d2",
   "metadata": {},
   "source": [
    "### Fit the best estimator on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.fit(x_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(x_test[features])\n",
    "\n",
    "\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed307d59",
   "metadata": {},
   "source": [
    "## Random forest and gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of parameters to test through cross-validation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "param_grid = {'max_depth': [10,20, 30, 50, 70]}\n",
    "grid_forest = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv=5)\n",
    "grid_forest.fit(x_valid[features], y_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36319",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_forest.best_estimator_.predict(x_test[features])\n",
    "print(grid_forest.best_estimator_)\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(x_train[features], y_train)\n",
    "y_pred = reg.predict(x_test[features])\n",
    "\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3-Assignment1-Aux.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
