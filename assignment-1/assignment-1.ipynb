{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2735c935",
   "metadata": {
    "id": "2735c935"
   },
   "source": [
    "<h1><center> Assignment 1: EDA United Nations General Debate Corpus  </center></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c94a6",
   "metadata": {},
   "source": [
    "## Read UNGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0b3ce3",
   "metadata": {
    "id": "cd0b3ce3",
    "outputId": "2389f396-4af3-408f-ead4-16e595e79676"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sessions = np.arange(25, 76)\n",
    "data=[]\n",
    "\n",
    "for session in sessions:\n",
    "    directory = \"./TXT/Session \"+str(session)+\" - \"+str(1945+session)\n",
    "    for filename in os.listdir(directory):\n",
    "        f = open(os.path.join(directory, filename))\n",
    "        if filename[0]==\".\": #ignore hidden files\n",
    "            continue\n",
    "        splt = filename.split(\"_\")\n",
    "        data.append([session, 1945+session, splt[0], f.read()])\n",
    "\n",
    "        \n",
    "df_speech = pd.DataFrame(data, columns=['Session','Year','ISO-alpha3 Code','Speech'])\n",
    "df_codes = pd.read_csv('UNSD — Methodology.csv', sep=';')\n",
    "\n",
    "df_un_merged = df_speech.merge(df_codes[['Country or Area','ISO-alpha3 Code']], how='left', left_on='ISO-alpha3 Code', right_on='ISO-alpha3 Code')\n",
    "df_un_merged.set_index(['Year','ISO-alpha3 Code'], inplace=True)\n",
    "df_un_merged[\"Speech\"] = df_un_merged[\"Speech\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804ea16",
   "metadata": {},
   "source": [
    "## Run bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bd027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(lowercase=True, \\\n",
    "                             stop_words='english',\\\n",
    "                             analyzer='word',\\\n",
    "                            token_pattern=r\"[a-z]+'?[a-z]+\", \\\n",
    "                            min_df=10, ngram_range=(1,1))\n",
    "X_counts = count_vect.fit_transform(df_un_merged[\"Speech\"])\n",
    "X_counts_tf = TfidfTransformer(use_idf=True).fit_transform(X_counts)\n",
    "words_list = count_vect.get_feature_names_out()\n",
    "#X_counts = pd.DataFrame(X_counts.toarray(), columns=words_list)\n",
    "X_counts = pd.DataFrame(X_counts_tf.toarray(), columns=words_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d413e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8481, 19361)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d17fa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ababa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abating</th>\n",
       "      <th>...</th>\n",
       "      <th>zimbabweans</th>\n",
       "      <th>zine</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zionists</th>\n",
       "      <th>zonal</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>0.031598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8481 rows × 19361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ababa   abandon  abandoned  abandoning  abandonment  abandons  abate  \\\n",
       "0     0.000000  0.037148        0.0    0.000000     0.000000       0.0    0.0   \n",
       "1     0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "2     0.000000  0.012760        0.0    0.000000     0.000000       0.0    0.0   \n",
       "3     0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "4     0.000000  0.000000        0.0    0.028921     0.000000       0.0    0.0   \n",
       "...        ...       ...        ...         ...          ...       ...    ...   \n",
       "8476  0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "8477  0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "8478  0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "8479  0.000000  0.000000        0.0    0.000000     0.000000       0.0    0.0   \n",
       "8480  0.031598  0.000000        0.0    0.000000     0.037156       0.0    0.0   \n",
       "\n",
       "      abated  abatement  abating  ...  zimbabweans  zine  zionism   zionist  \\\n",
       "0        0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "1        0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "2        0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "3        0.0        0.0      0.0  ...          0.0   0.0      0.0  0.110391   \n",
       "4        0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "...      ...        ...      ...  ...          ...   ...      ...       ...   \n",
       "8476     0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "8477     0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "8478     0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "8479     0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "8480     0.0        0.0      0.0  ...          0.0   0.0      0.0  0.000000   \n",
       "\n",
       "      zionists  zonal      zone     zones  zuma  zurich  \n",
       "0          0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "1          0.0    0.0  0.019275  0.000000   0.0     0.0  \n",
       "2          0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "3          0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "4          0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "...        ...    ...       ...       ...   ...     ...  \n",
       "8476       0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "8477       0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "8478       0.0    0.0  0.000000  0.016045   0.0     0.0  \n",
       "8479       0.0    0.0  0.000000  0.000000   0.0     0.0  \n",
       "8480       0.0    0.0  0.000000  0.022986   0.0     0.0  \n",
       "\n",
       "[8481 rows x 19361 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8ea62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ababa          10.668102\n",
       "abandon        15.650344\n",
       "abandoned       8.527856\n",
       "abandoning      4.311010\n",
       "abandonment     4.542406\n",
       "                 ...    \n",
       "zonal           1.041193\n",
       "zone           45.346667\n",
       "zones          26.042332\n",
       "zuma            0.830193\n",
       "zurich          0.457641\n",
       "Length: 19361, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24020e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ISO-alpha3 Code</th>\n",
       "      <th>Session</th>\n",
       "      <th>Speech</th>\n",
       "      <th>Country or Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>LBR</td>\n",
       "      <td>25</td>\n",
       "      <td>49.\\t it gives me great pleasure, mr. presiden...</td>\n",
       "      <td>Liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>HND</td>\n",
       "      <td>25</td>\n",
       "      <td>153.\\t  this session of the general assembly w...</td>\n",
       "      <td>Honduras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>KHM</td>\n",
       "      <td>25</td>\n",
       "      <td>4.\\t before i begin this speech i should like ...</td>\n",
       "      <td>Cambodia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>TUN</td>\n",
       "      <td>25</td>\n",
       "      <td>83.\\t  mr. president, it is my pleasure to spe...</td>\n",
       "      <td>Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>BRA</td>\n",
       "      <td>25</td>\n",
       "      <td>1.\\tmr. president, i should like, first of all...</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>2020</td>\n",
       "      <td>CPV</td>\n",
       "      <td>75</td>\n",
       "      <td>mr. president of the general assembly,\\nexcell...</td>\n",
       "      <td>Cabo Verde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>2020</td>\n",
       "      <td>ARE</td>\n",
       "      <td>75</td>\n",
       "      <td>mr. president,\\nat the outset, i would like to...</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>2020</td>\n",
       "      <td>GEO</td>\n",
       "      <td>75</td>\n",
       "      <td>mr. president,\\nmr. secretary-general,\\nesteem...</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>2020</td>\n",
       "      <td>CAN</td>\n",
       "      <td>75</td>\n",
       "      <td>mr. president, fellow delegates, my friends.\\n...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>2020</td>\n",
       "      <td>LUX</td>\n",
       "      <td>75</td>\n",
       "      <td>mr. president,\\nladies and gentlemen,\\ndear fr...</td>\n",
       "      <td>Luxembourg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8481 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year ISO-alpha3 Code  Session  \\\n",
       "0     1970             LBR       25   \n",
       "1     1970             HND       25   \n",
       "2     1970             KHM       25   \n",
       "3     1970             TUN       25   \n",
       "4     1970             BRA       25   \n",
       "...    ...             ...      ...   \n",
       "8476  2020             CPV       75   \n",
       "8477  2020             ARE       75   \n",
       "8478  2020             GEO       75   \n",
       "8479  2020             CAN       75   \n",
       "8480  2020             LUX       75   \n",
       "\n",
       "                                                 Speech       Country or Area  \n",
       "0     49.\\t it gives me great pleasure, mr. presiden...               Liberia  \n",
       "1     153.\\t  this session of the general assembly w...              Honduras  \n",
       "2     4.\\t before i begin this speech i should like ...              Cambodia  \n",
       "3     83.\\t  mr. president, it is my pleasure to spe...               Tunisia  \n",
       "4     1.\\tmr. president, i should like, first of all...                Brazil  \n",
       "...                                                 ...                   ...  \n",
       "8476  mr. president of the general assembly,\\nexcell...            Cabo Verde  \n",
       "8477  mr. president,\\nat the outset, i would like to...  United Arab Emirates  \n",
       "8478  mr. president,\\nmr. secretary-general,\\nesteem...               Georgia  \n",
       "8479  mr. president, fellow delegates, my friends.\\n...                Canada  \n",
       "8480  mr. president,\\nladies and gentlemen,\\ndear fr...            Luxembourg  \n",
       "\n",
       "[8481 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un_merged.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87532eb",
   "metadata": {},
   "source": [
    "## Merge UNGDC with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f164286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un_merged = df_un_merged.reset_index().merge(X_counts, how='left', left_index=True, right_index=True)\n",
    "df_un_merged.set_index(['Year','ISO-alpha3 Code'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625760ad",
   "metadata": {},
   "source": [
    "## Read happiness report and merge with country codes to get ISO-alpha3 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9aa614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happinessdataframe = pd.read_excel('DataForTable2.1.xls')\n",
    "df_happiness_merged = happinessdataframe.merge(df_codes[['Country or Area','ISO-alpha3 Code']], how='left', left_on='Country name', right_on='Country or Area')\n",
    "df_happiness_merged.set_index(['year','ISO-alpha3 Code'], inplace=True)\n",
    "df_happiness_merged.index.rename(['Year','ISO-alpha3 Code'], inplace=True)\n",
    "df_happiness_merged.drop(columns=['Country name','Country or Area'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58defa",
   "metadata": {},
   "source": [
    "## Merge UNGDC with happiness report by Multiple index Year, ISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9710c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un_merged = df_un_merged.merge(df_happiness_merged, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67242e61",
   "metadata": {},
   "source": [
    "## Build Regression for Life Ladder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d235135",
   "metadata": {},
   "source": [
    "### remove NaN rows from Life Ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc1d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove na from rows\n",
    "x=df_un_merged.dropna(subset=['Life Ladder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57775e",
   "metadata": {},
   "source": [
    "### Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a104d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "y = x['Life Ladder'].values\n",
    "\n",
    "# splitting the data\n",
    "x_rem, x_test, y_rem, y_test = train_test_split(x, y, test_size=0.3, random_state = 42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_rem, y_rem, test_size=0.3, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cf308",
   "metadata": {},
   "source": [
    "### Hyperparameters tunning based grid search on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f71ee816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/preprocessing/_polynomial.py\", line 422, in transform\n",
      "    shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 395. GiB for an array with shape (283, 187453203) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/preprocessing/_polynomial.py\", line 422, in transform\n",
      "    shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 397. GiB for an array with shape (284, 187453203) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/preprocessing/_polynomial.py\", line 422, in transform\n",
      "    shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.43 PiB for an array with shape (283, 1209947940964) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/wolfson/.local/lib/python3.7/site-packages/sklearn/preprocessing/_polynomial.py\", line 422, in transform\n",
      "    shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.44 PiB for an array with shape (284, 1209947940964) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/wolfson/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.62251082        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# Create grid of parameters to test through cross-validation\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(1,3)}\n",
    "\n",
    "pipe = make_pipeline( PolynomialFeatures(), LinearRegression())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(x_valid[words_list], y_valid);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb084d2",
   "metadata": {},
   "source": [
    "### Fit the best estimator on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "780bf609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=1)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.fit(x_train[words_list], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ec6df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:\n",
      "Mean squared error: 0.32\n",
      "Variance score: 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(x_test[words_list])\n",
    "\n",
    "\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79c6f912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFG',\n",
       " 'AGO',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ARG',\n",
       " 'ARM',\n",
       " 'AUS',\n",
       " 'AUT',\n",
       " 'AZE',\n",
       " 'BDI',\n",
       " 'BEL',\n",
       " 'BEN',\n",
       " 'BFA',\n",
       " 'BGD',\n",
       " 'BGR',\n",
       " 'BHR',\n",
       " 'BIH',\n",
       " 'BLR',\n",
       " 'BRA',\n",
       " 'BTN',\n",
       " 'BWA',\n",
       " 'CAN',\n",
       " 'CHE',\n",
       " 'CHL',\n",
       " 'CHN',\n",
       " 'CMR',\n",
       " 'COL',\n",
       " 'CRI',\n",
       " 'CYP',\n",
       " 'CZE',\n",
       " 'DEU',\n",
       " 'DNK',\n",
       " 'DZA',\n",
       " 'ECU',\n",
       " 'EGY',\n",
       " 'ESP',\n",
       " 'EST',\n",
       " 'ETH',\n",
       " 'FIN',\n",
       " 'FRA',\n",
       " 'GAB',\n",
       " 'GEO',\n",
       " 'GHA',\n",
       " 'GIN',\n",
       " 'GRC',\n",
       " 'GTM',\n",
       " 'HND',\n",
       " 'HRV',\n",
       " 'HTI',\n",
       " 'HUN',\n",
       " 'IDN',\n",
       " 'IND',\n",
       " 'IRL',\n",
       " 'IRQ',\n",
       " 'ISL',\n",
       " 'ISR',\n",
       " 'ITA',\n",
       " 'JAM',\n",
       " 'JOR',\n",
       " 'JPN',\n",
       " 'KAZ',\n",
       " 'KEN',\n",
       " 'KGZ',\n",
       " 'KHM',\n",
       " 'KWT',\n",
       " 'LBN',\n",
       " 'LBR',\n",
       " 'LBY',\n",
       " 'LKA',\n",
       " 'LSO',\n",
       " 'LTU',\n",
       " 'LUX',\n",
       " 'LVA',\n",
       " 'MAR',\n",
       " 'MDG',\n",
       " 'MEX',\n",
       " 'MKD',\n",
       " 'MLI',\n",
       " 'MLT',\n",
       " 'MMR',\n",
       " 'MNE',\n",
       " 'MNG',\n",
       " 'MOZ',\n",
       " 'MRT',\n",
       " 'MUS',\n",
       " 'MWI',\n",
       " 'MYS',\n",
       " 'NAM',\n",
       " 'NER',\n",
       " 'NGA',\n",
       " 'NIC',\n",
       " 'NLD',\n",
       " 'NOR',\n",
       " 'NPL',\n",
       " 'NZL',\n",
       " 'PAK',\n",
       " 'PAN',\n",
       " 'PER',\n",
       " 'PHL',\n",
       " 'POL',\n",
       " 'PRT',\n",
       " 'PRY',\n",
       " 'QAT',\n",
       " 'ROU',\n",
       " 'RWA',\n",
       " 'SDN',\n",
       " 'SEN',\n",
       " 'SGP',\n",
       " 'SLE',\n",
       " 'SLV',\n",
       " 'SOM',\n",
       " 'SRB',\n",
       " 'SUR',\n",
       " 'SVK',\n",
       " 'SVN',\n",
       " 'SWE',\n",
       " 'SWZ',\n",
       " 'TCD',\n",
       " 'TGO',\n",
       " 'THA',\n",
       " 'TJK',\n",
       " 'TKM',\n",
       " 'TTO',\n",
       " 'TUN',\n",
       " 'UGA',\n",
       " 'UKR',\n",
       " 'URY',\n",
       " 'UZB',\n",
       " 'YEM',\n",
       " 'ZAF',\n",
       " 'ZMB',\n",
       " 'ZWE'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " set(x_test.reset_index()['ISO-alpha3 Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76e71bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fddd5c136d0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = words_list.tolist()\n",
    "a.append('Life Ladder')\n",
    "data = x_test.loc[:,'UKR',:][a].reset_index()\n",
    "y_pred_country = grid.best_estimator_.predict(data[words_list])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(data['Year'],data['Life Ladder'], c='black')\n",
    "ax.plot(data['Year'],y_pred_country, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of parameters to test through cross-validation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "param_grid = {'max_depth': [10,50, 100, 200, 300]}\n",
    "grid_forest = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "grid_forest.fit(x_valid, y_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36319",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_forest.best_estimator_.predict(x_test)\n",
    "grid_forest.best_estimator_\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(0,len(y_test)),y_test, c='black')\n",
    "ax.scatter(np.arange(0,len(y_pred)),y_pred, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "# Compute test error and variance score\n",
    "print(\"Model accuracy:\")\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(0,len(y_test)),y_test, c='black')\n",
    "ax.scatter(np.arange(0,len(y_pred)),y_pred, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4cfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43967462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3-Assignment1-Aux.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
